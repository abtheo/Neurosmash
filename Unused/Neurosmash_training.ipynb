{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4b5BMoPxcry2"
   },
   "source": [
    "#Neurosmash Training\n",
    "Notebook for training models, thanks Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiI6ocezc2pw"
   },
   "source": [
    "##Mount GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "zYP0tUzfdG-c",
    "outputId": "0fd99646-2af6-4390-885c-bf64b67cf4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive/', force_remount=True)\n",
    "\n",
    "root_dir = '/content/drive/My Drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0oxa_QaduSa"
   },
   "source": [
    "##Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4D4tp3idv0L"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import socket\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xwgu6ugkdUC-"
   },
   "source": [
    "#Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LjcSOhLHdXVm",
    "outputId": "a9d4fc4a-a254-43a6-907d-aac20d490f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "experience_replay = None\n",
    "with open(root_dir + \"/NIPS/randomwalk_1.pkl\", 'rb') as f:\n",
    "    experience_replay = pickle.load(f)\n",
    "\n",
    "print(len(experience_replay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ub8oykAYdxrM"
   },
   "source": [
    "#Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9kzDjH6d081"
   },
   "outputs": [],
   "source": [
    "class NeurosmashAgent(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeurosmashAgent, self).__init__()\n",
    "        #Shape of input image\n",
    "        self.state_shape = (256, 256, 3)\n",
    "        #Size of action space (Nothing, Left, Right)\n",
    "        self.num_actions = 3\n",
    "        \n",
    "        #Input channels = 3, output channels = 256\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        #256, 256, 64\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        #128, 128, 64\n",
    "        self.conv2 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        #128, 128, 128\n",
    "        \n",
    "        #self.pool again\n",
    "        #64, 64, 128\n",
    "\n",
    "        self.linear = torch.nn.Linear(64*64*128, 128)\n",
    "\n",
    "        self.output = torch.nn.Linear(128, self.num_actions)\n",
    "        #3 output channels (Nothing=0, Left=1, Right=2)\n",
    "        \n",
    "\n",
    "    def step(self, state):\n",
    "        # return 0 # no action\n",
    "        # return 1 # left action\n",
    "        # return 2 # right action\n",
    "        # return 3 # built-in random action\n",
    "        \n",
    "        #TODO: Check this view transformation actually produces an image\n",
    "        state = torch.tensor(state, dtype=torch.float).view(3, 256, 256).view(1,3,256,256).float()\n",
    "        \n",
    "        action = self.forward(state)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Convolution layer, ReLU activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #MaxPooling2D\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #Flatten pooled layer\n",
    "        x = x.view(-1, 64 * 64 * 128)\n",
    "\n",
    "        #Linear layer\n",
    "        x = F.relu(self.linear(x))\n",
    "\n",
    "        #Dropout\n",
    "        x = F.dropout(x, 0.2, training=self.training)\n",
    "\n",
    "        #Softmax on linear output layer\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmAOxgB4fDjm"
   },
   "source": [
    "#Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_1xBqRREfC43",
    "outputId": "7a80fab6-eb06-428f-bc21-c26a2a54f0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeurosmashAgent(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (linear): Linear(in_features=524288, out_features=128, bias=True)\n",
      "  (output): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "[1,     1,   180] loss: 0.968\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.6661e-05, 9.9998e-01, 9.7647e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,     2,   162] loss: 0.910\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.8477e-02, 9.6138e-01, 1.4036e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,     3,   224] loss: 0.914\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9996e-01, 3.6569e-05, 6.0845e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,     4,   190] loss: 0.917\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0253, 0.1043, 0.8704]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,     5,   253] loss: 0.955\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0359, 0.4149, 0.5492]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,     6,   229] loss: 0.916\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0409, 0.4442, 0.5149]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,     7,   250] loss: 0.964\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2030, 0.4244, 0.3725]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,     8,   300] loss: 0.980\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[9.7440e-07, 1.0000e+00, 6.6780e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,     9,   216] loss: 0.863\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0320, 0.3416, 0.6264]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    10,   208] loss: 0.889\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.6705e-04, 5.2104e-07, 9.9983e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    11,   224] loss: 0.934\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[8.6034e-04, 9.9909e-01, 4.8939e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    12,   173] loss: 0.980\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9950, 0.0015, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    13,   218] loss: 0.928\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0113, 0.9170, 0.0717]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    14,   218] loss: 0.943\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0084, 0.9750, 0.0165]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    15,   210] loss: 0.910\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9026e-01, 8.6800e-04, 8.8705e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    16,   175] loss: 0.991\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0179, 0.8039, 0.1782]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    17,   235] loss: 0.878\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0776, 0.6866, 0.2358]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    18,   181] loss: 1.013\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.3452e-01, 2.7755e-04, 6.5201e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    19,   226] loss: 0.894\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9925e-01, 2.5433e-04, 4.9705e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    20,   178] loss: 0.939\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4150, 0.3011, 0.2839]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[1,    21,   205] loss: 0.891\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 1.5357e-06, 1.1361e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    22,   162] loss: 0.892\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.5378e-09, 1.3281e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[1,    23,   166] loss: 0.910\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.0564e-09, 4.1927e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,     1,   180] loss: 0.966\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.2378e-05, 9.9998e-01, 1.0658e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,     2,   162] loss: 0.898\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.7660e-03, 9.9704e-01, 1.9092e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,     3,   224] loss: 0.901\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9986e-01, 3.8297e-05, 9.9787e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,     4,   190] loss: 0.922\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0505, 0.8248, 0.1247]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,     5,   253] loss: 0.930\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0678, 0.2018, 0.7304]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,     6,   229] loss: 0.921\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0330, 0.2192, 0.7478]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,     7,   250] loss: 0.957\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2686, 0.3994, 0.3320]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,     8,   300] loss: 0.956\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.4198e-07, 1.0000e+00, 4.2561e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,     9,   216] loss: 0.853\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0024, 0.1278, 0.8699]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    10,   208] loss: 0.873\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.8785e-05, 2.7254e-06, 9.9998e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    11,   224] loss: 0.928\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.8730e-04, 9.9939e-01, 2.3114e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    12,   173] loss: 0.978\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9945, 0.0015, 0.0041]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    13,   218] loss: 0.893\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.2953e-05, 9.9880e-01, 1.1362e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    14,   218] loss: 0.935\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0067, 0.9721, 0.0212]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    15,   210] loss: 0.917\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9904, 0.0040, 0.0056]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    16,   175] loss: 0.959\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0197, 0.8146, 0.1657]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    17,   235] loss: 0.883\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.2988, 0.5088, 0.1923]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    18,   181] loss: 0.988\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9644e-01, 1.3717e-04, 3.4194e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    19,   226] loss: 0.883\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9966e-01, 7.0595e-06, 3.3544e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    20,   178] loss: 0.948\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4031, 0.3115, 0.2855]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[2,    21,   205] loss: 0.885\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 1.0985e-07, 1.1248e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    22,   162] loss: 0.912\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.9737e-07, 2.1926e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[2,    23,   166] loss: 0.895\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9618e-01, 6.5080e-09, 3.8174e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,     1,   180] loss: 0.975\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.8007e-04, 9.9952e-01, 7.6449e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,     2,   162] loss: 0.910\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.1940e-03, 9.9680e-01, 4.3672e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,     3,   224] loss: 0.894\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9866e-01, 1.0770e-03, 2.6228e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,     4,   190] loss: 0.913\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0658, 0.1466, 0.7876]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,     5,   253] loss: 0.923\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1243, 0.2549, 0.6208]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,     6,   229] loss: 0.889\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0511, 0.2028, 0.7461]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,     7,   250] loss: 0.938\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3016, 0.3724, 0.3260]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,     8,   300] loss: 0.963\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.6466e-07, 1.0000e+00, 1.4505e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,     9,   216] loss: 0.830\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[5.9023e-06, 4.1587e-02, 9.5841e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    10,   208] loss: 0.865\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[5.0149e-05, 5.9779e-06, 9.9994e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    11,   224] loss: 0.928\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.4900e-03, 9.9551e-01, 4.4526e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    12,   173] loss: 0.965\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9928e-01, 2.4510e-04, 4.7858e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    13,   218] loss: 0.893\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0041, 0.9487, 0.0472]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,    14,   218] loss: 0.912\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0035, 0.9473, 0.0492]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,    15,   210] loss: 0.921\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9908, 0.0029, 0.0063]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,    16,   175] loss: 0.974\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0255, 0.5465, 0.4280]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,    17,   235] loss: 0.861\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.3982, 0.4323, 0.1695]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,    18,   181] loss: 1.017\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9922e-01, 1.0894e-06, 7.8287e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    19,   226] loss: 0.890\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9997e-01, 4.6469e-06, 2.5144e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    20,   178] loss: 0.939\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.3355, 0.3659, 0.2986]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[3,    21,   205] loss: 0.850\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9979e-01, 9.3173e-08, 2.0520e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    22,   162] loss: 0.891\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 4.3262e-07, 9.9776e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[3,    23,   166] loss: 0.915\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.1595e-09, 3.9655e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,     1,   180] loss: 0.976\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.0963e-05, 9.9997e-01, 5.4255e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,     2,   162] loss: 0.897\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.7404e-02, 9.8260e-01, 5.2040e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,     3,   224] loss: 0.887\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9997e-01, 3.0897e-05, 2.8050e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,     4,   190] loss: 0.888\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0099, 0.0399, 0.9502]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,     5,   253] loss: 0.921\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0830, 0.1862, 0.7309]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,     6,   229] loss: 0.875\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0263, 0.0075, 0.9662]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,     7,   250] loss: 0.953\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2638, 0.4285, 0.3076]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,     8,   300] loss: 0.951\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[9.7455e-07, 1.0000e+00, 1.0574e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,     9,   216] loss: 0.865\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0091, 0.0215, 0.9695]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,    10,   208] loss: 0.875\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[4.5326e-05, 1.2085e-07, 9.9995e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    11,   224] loss: 0.943\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.0494e-04, 9.9289e-01, 6.8039e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    12,   173] loss: 0.923\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9974e-01, 1.6692e-04, 8.9178e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    13,   218] loss: 0.858\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.0206e-05, 9.9876e-01, 1.2074e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    14,   218] loss: 0.931\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.1623, 0.7399, 0.0978]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,    15,   210] loss: 0.931\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.4742, 0.3028, 0.2230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,    16,   175] loss: 0.955\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0231, 0.7407, 0.2362]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,    17,   235] loss: 0.843\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.3890, 0.3937, 0.2173]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,    18,   181] loss: 0.987\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9020e-01, 2.9772e-06, 9.7929e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    19,   226] loss: 0.885\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9864e-01, 3.6051e-04, 9.9531e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    20,   178] loss: 0.917\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4280, 0.3297, 0.2424]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[4,    21,   205] loss: 0.870\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9974e-01, 1.1603e-10, 2.5749e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    22,   162] loss: 0.857\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 9.6939e-10, 1.3214e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[4,    23,   166] loss: 0.912\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 4.5946e-09, 2.9580e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,     1,   180] loss: 0.954\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.8400e-03, 9.9516e-01, 1.4580e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,     2,   162] loss: 0.919\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.3922e-01, 8.6077e-01, 8.6124e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,     3,   224] loss: 0.860\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9995e-01, 3.7041e-07, 4.9366e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,     4,   190] loss: 0.881\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0188, 0.1896, 0.7916]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,     5,   253] loss: 0.904\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1862, 0.3671, 0.4467]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,     6,   229] loss: 0.859\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0759, 0.0278, 0.8962]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,     7,   250] loss: 0.939\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2544, 0.3270, 0.4186]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,     8,   300] loss: 0.943\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.1378e-06, 1.0000e+00, 5.2025e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,     9,   216] loss: 0.840\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[4.2700e-06, 6.7358e-03, 9.9326e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    10,   208] loss: 0.848\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.8995e-05, 8.3545e-06, 9.9996e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    11,   224] loss: 0.904\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.9721e-04, 9.9940e-01, 5.5667e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    12,   173] loss: 0.952\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9981e-01, 2.0483e-05, 1.6912e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    13,   218] loss: 0.904\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.2003e-05, 9.9976e-01, 1.8790e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    14,   218] loss: 0.906\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.2849, 0.3180, 0.3972]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,    15,   210] loss: 0.900\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9950, 0.0027, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,    16,   175] loss: 0.963\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0621, 0.6740, 0.2639]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,    17,   235] loss: 0.852\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.4793, 0.3803, 0.1404]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,    18,   181] loss: 0.976\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9490e-01, 4.8154e-06, 5.0968e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    19,   226] loss: 0.917\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9789e-01, 4.0156e-04, 1.7053e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    20,   178] loss: 0.896\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4403, 0.3067, 0.2530]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[5,    21,   205] loss: 0.834\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9535e-01, 1.4730e-08, 4.6540e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    22,   162] loss: 0.862\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 5.2703e-06, 7.9905e-12]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[5,    23,   166] loss: 0.888\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 5.4158e-10, 1.2077e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,     1,   180] loss: 0.925\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.4187e-03, 9.9758e-01, 5.0240e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,     2,   162] loss: 0.904\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.9883e-04, 9.9950e-01, 1.5024e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,     3,   224] loss: 0.859\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 8.6104e-06, 2.6261e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,     4,   190] loss: 0.891\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0530, 0.3071, 0.6399]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,     5,   253] loss: 0.931\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1358, 0.4512, 0.4131]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,     6,   229] loss: 0.871\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0332, 0.5070, 0.4598]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,     7,   250] loss: 0.939\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2260, 0.3951, 0.3789]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,     8,   300] loss: 0.923\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.1713e-07, 1.0000e+00, 2.2201e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,     9,   216] loss: 0.845\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.0993e-04, 7.8173e-03, 9.9207e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    10,   208] loss: 0.853\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.8968e-08, 1.3196e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    11,   224] loss: 0.891\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.1953e-04, 9.9988e-01, 1.0530e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    12,   173] loss: 0.958\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9706e-01, 2.1502e-03, 7.8716e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    13,   218] loss: 0.906\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0098, 0.9869, 0.0033]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,    14,   218] loss: 0.909\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0724, 0.7010, 0.2265]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,    15,   210] loss: 0.866\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.8899, 0.0047, 0.1054]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,    16,   175] loss: 0.941\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0051, 0.7840, 0.2108]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,    17,   235] loss: 0.819\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.1004, 0.7939, 0.1056]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,    18,   181] loss: 0.965\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9881e-01, 1.1093e-06, 1.1910e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    19,   226] loss: 0.877\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9926e-01, 1.9839e-04, 5.4617e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    20,   178] loss: 0.898\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.5467, 0.2130, 0.2403]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[6,    21,   205] loss: 0.818\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.7048e-14, 1.2496e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    22,   162] loss: 0.858\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 9.8686e-15, 3.2770e-12]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[6,    23,   166] loss: 0.888\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 8.0760e-08, 1.3841e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,     1,   180] loss: 0.932\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.6947e-06, 9.9999e-01, 5.2868e-13]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,     2,   162] loss: 0.896\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.1554e-04, 9.9988e-01, 5.7412e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,     3,   224] loss: 0.883\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9994e-01, 1.0632e-05, 4.6409e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,     4,   190] loss: 0.914\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0785, 0.4405, 0.4810]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,     5,   253] loss: 0.901\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0489, 0.5448, 0.4063]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,     6,   229] loss: 0.836\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0192, 0.0136, 0.9672]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,     7,   250] loss: 0.948\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2297, 0.3461, 0.4242]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,     8,   300] loss: 0.926\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.0132e-10, 1.0000e+00, 6.1609e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,     9,   216] loss: 0.858\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.0070e-04, 3.4107e-02, 9.6579e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    10,   208] loss: 0.846\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.2105e-06, 9.0305e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    11,   224] loss: 0.898\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.0461e-05, 9.9999e-01, 1.8254e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    12,   173] loss: 0.929\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9981e-01, 3.0934e-06, 1.8867e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    13,   218] loss: 0.873\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.7802e-06, 8.9096e-01, 1.0904e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    14,   218] loss: 0.892\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0054, 0.2770, 0.7176]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,    15,   210] loss: 0.885\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.8564, 0.1345, 0.0090]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,    16,   175] loss: 0.921\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0112, 0.8004, 0.1884]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,    17,   235] loss: 0.832\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.5820, 0.1050, 0.3130]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,    18,   181] loss: 0.988\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9307e-01, 1.1074e-06, 6.9315e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    19,   226] loss: 0.873\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9711e-01, 1.6905e-04, 2.7167e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    20,   178] loss: 0.885\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.2731, 0.3969, 0.3300]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[7,    21,   205] loss: 0.832\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 7.7047e-09, 3.4835e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    22,   162] loss: 0.879\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.9193e-10, 1.0606e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[7,    23,   166] loss: 0.864\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9996e-01, 6.1218e-09, 3.9640e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,     1,   180] loss: 0.926\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.6717e-05, 9.9997e-01, 7.9620e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,     2,   162] loss: 0.865\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.3253e-04, 9.9937e-01, 3.3747e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,     3,   224] loss: 0.873\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9934e-01, 1.1312e-04, 5.4389e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,     4,   190] loss: 0.892\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0378, 0.1492, 0.8129]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,     5,   253] loss: 0.911\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0730, 0.1983, 0.7288]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,     6,   229] loss: 0.856\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0013, 0.0217, 0.9771]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,     7,   250] loss: 0.930\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3808, 0.3313, 0.2878]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,     8,   300] loss: 0.926\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.4101e-10, 1.0000e+00, 6.6925e-16]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,     9,   216] loss: 0.839\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[5.4918e-07, 4.1410e-02, 9.5859e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    10,   208] loss: 0.842\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.5893e-09, 1.2233e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    11,   224] loss: 0.873\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.9715e-06, 1.0000e+00, 2.1694e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    12,   173] loss: 0.926\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 4.2130e-07, 1.1373e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    13,   218] loss: 0.860\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.2772e-06, 9.9997e-01, 2.3693e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    14,   218] loss: 0.879\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0998, 0.0907, 0.8095]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,    15,   210] loss: 0.861\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.8728, 0.1061, 0.0210]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,    16,   175] loss: 0.927\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0021, 0.8688, 0.1291]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,    17,   235] loss: 0.807\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.3193, 0.4187, 0.2619]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,    18,   181] loss: 0.967\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9767e-01, 7.2431e-07, 2.3328e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    19,   226] loss: 0.859\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9992e-01, 1.2025e-05, 7.1134e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    20,   178] loss: 0.872\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.3807, 0.3148, 0.3044]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[8,    21,   205] loss: 0.811\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.7136e-12, 1.9219e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    22,   162] loss: 0.847\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.7707e-11, 1.1505e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[8,    23,   166] loss: 0.846\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 8.7991e-08, 3.3506e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,     1,   180] loss: 0.930\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.7402e-08, 1.0000e+00, 4.3881e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,     2,   162] loss: 0.894\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.3185e-03, 9.9868e-01, 5.0900e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,     3,   224] loss: 0.844\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 3.1837e-07, 1.7814e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,     4,   190] loss: 0.874\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0778, 0.2380, 0.6842]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,     5,   253] loss: 0.881\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0864, 0.5501, 0.3635]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,     6,   229] loss: 0.856\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0177, 0.8468, 0.1355]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,     7,   250] loss: 0.921\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3247, 0.3464, 0.3289]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,     8,   300] loss: 0.921\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.4743e-10, 1.0000e+00, 1.9570e-13]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,     9,   216] loss: 0.825\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[7.1792e-09, 1.8609e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    10,   208] loss: 0.845\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[6.6634e-08, 7.8731e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    11,   224] loss: 0.891\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.2949e-05, 9.9997e-01, 2.2692e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    12,   173] loss: 0.937\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 9.0579e-09, 1.4313e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    13,   218] loss: 0.858\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[8.3446e-06, 9.9999e-01, 1.5756e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    14,   218] loss: 0.885\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0024, 0.9939, 0.0037]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,    15,   210] loss: 0.892\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9885, 0.0080, 0.0036]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,    16,   175] loss: 0.913\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0504, 0.3634, 0.5862]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,    17,   235] loss: 0.799\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.4315, 0.3320, 0.2365]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,    18,   181] loss: 0.942\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9483e-01, 5.0331e-07, 5.1724e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    19,   226] loss: 0.832\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9894e-01, 1.1320e-04, 9.4956e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    20,   178] loss: 0.912\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.5322, 0.2217, 0.2461]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[9,    21,   205] loss: 0.809\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.6928e-15, 3.6120e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    22,   162] loss: 0.843\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.4527e-08, 1.9770e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[9,    23,   166] loss: 0.845\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 9.2233e-13, 6.3564e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,     1,   180] loss: 0.910\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.7489e-07, 1.0000e+00, 1.3905e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,     2,   162] loss: 0.869\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.3088e-04, 9.9947e-01, 7.9769e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,     3,   224] loss: 0.861\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 3.5357e-06, 8.2441e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,     4,   190] loss: 0.868\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0363, 0.2880, 0.6757]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,     5,   253] loss: 0.886\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1600, 0.4809, 0.3591]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,     6,   229] loss: 0.833\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0095, 0.0915, 0.8991]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,     7,   250] loss: 0.910\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3270, 0.3457, 0.3273]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,     8,   300] loss: 0.908\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.5969e-05, 9.9998e-01, 1.0229e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,     9,   216] loss: 0.839\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.6411e-05, 8.1441e-01, 1.8558e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    10,   208] loss: 0.837\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[3.5404e-04, 1.9398e-07, 9.9965e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    11,   224] loss: 0.913\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[8.6104e-04, 9.9914e-01, 1.7140e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    12,   173] loss: 0.921\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9997e-01, 5.9539e-09, 3.4213e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    13,   218] loss: 0.855\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.1462e-05, 9.9983e-01, 1.3415e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    14,   218] loss: 0.869\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0070, 0.2877, 0.7053]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,    15,   210] loss: 0.871\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9997e-01, 1.2994e-05, 1.4583e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    16,   175] loss: 0.900\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0019, 0.8396, 0.1585]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,    17,   235] loss: 0.785\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.1109, 0.5955, 0.2935]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,    18,   181] loss: 0.944\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9785e-01, 1.6708e-07, 2.1491e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    19,   226] loss: 0.873\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9976e-01, 7.9608e-06, 2.3637e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    20,   178] loss: 0.862\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4224, 0.2834, 0.2942]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[10,    21,   205] loss: 0.832\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.4294e-08, 4.3264e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    22,   162] loss: 0.841\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 4.5347e-13, 1.2238e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[10,    23,   166] loss: 0.843\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.5504e-12, 2.2075e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,     1,   180] loss: 0.911\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.9285e-06, 1.0000e+00, 7.2848e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,     2,   162] loss: 0.850\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.2504e-04, 9.9987e-01, 1.6369e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,     3,   224] loss: 0.836\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 7.8250e-07, 1.0546e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,     4,   190] loss: 0.876\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0485, 0.3273, 0.6242]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,     5,   253] loss: 0.877\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0043, 0.0032, 0.9924]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,     6,   229] loss: 0.859\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0058, 0.1696, 0.8246]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,     7,   250] loss: 0.916\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2969, 0.3482, 0.3549]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,     8,   300] loss: 0.892\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.7090e-10, 1.0000e+00, 8.8945e-17]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,     9,   216] loss: 0.822\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.5631e-08, 5.1889e-04, 9.9948e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    10,   208] loss: 0.827\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[3.3253e-06, 4.2826e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    11,   224] loss: 0.864\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.2781e-06, 1.0000e+00, 1.7879e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    12,   173] loss: 0.905\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.7624e-08, 1.2644e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    13,   218] loss: 0.834\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[8.2870e-06, 9.9984e-01, 1.5129e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    14,   218] loss: 0.863\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.6570e-04, 7.1409e-01, 2.8575e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    15,   210] loss: 0.868\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9992e-01, 1.3907e-05, 6.1894e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    16,   175] loss: 0.908\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0432, 0.9198, 0.0370]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,    17,   235] loss: 0.798\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.2515, 0.6145, 0.1340]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,    18,   181] loss: 0.954\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9996e-01, 5.0068e-09, 3.8136e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    19,   226] loss: 0.824\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.1600e-08, 4.1683e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    20,   178] loss: 0.886\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.3880, 0.3713, 0.2407]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[11,    21,   205] loss: 0.814\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 9.2721e-14, 1.1035e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    22,   162] loss: 0.846\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.5294e-14, 4.3818e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[11,    23,   166] loss: 0.860\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.3929e-14, 6.7253e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,     1,   180] loss: 0.936\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.2894e-06, 1.0000e+00, 2.9223e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,     2,   162] loss: 0.875\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.0895e-04, 9.9989e-01, 1.0165e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,     3,   224] loss: 0.820\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 5.0568e-06, 1.9583e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,     4,   190] loss: 0.853\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0148, 0.1810, 0.8042]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,     5,   253] loss: 0.855\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0893, 0.1795, 0.7313]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,     6,   229] loss: 0.847\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[8.8999e-04, 9.3537e-01, 6.3738e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,     7,   250] loss: 0.916\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.4550, 0.2500, 0.2950]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,     8,   300] loss: 0.903\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.5088e-10, 1.0000e+00, 1.7943e-17]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,     9,   216] loss: 0.829\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.7881e-06, 1.6136e-04, 9.9984e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    10,   208] loss: 0.819\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[3.0601e-07, 5.2839e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    11,   224] loss: 0.911\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.0407e-06, 1.0000e+00, 4.7219e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    12,   173] loss: 0.903\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9934e-01, 8.1009e-07, 6.6037e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    13,   218] loss: 0.839\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.8272e-07, 9.9987e-01, 1.2788e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    14,   218] loss: 0.859\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.2940, 0.4123, 0.2937]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,    15,   210] loss: 0.852\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9930e-01, 2.1421e-04, 4.8907e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    16,   175] loss: 0.896\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0053, 0.6151, 0.3797]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,    17,   235] loss: 0.792\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.5458, 0.2214, 0.2328]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,    18,   181] loss: 0.948\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9997e-01, 3.6528e-08, 2.7733e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    19,   226] loss: 0.820\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9972e-01, 2.0693e-05, 2.5636e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    20,   178] loss: 0.861\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4813, 0.2908, 0.2279]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[12,    21,   205] loss: 0.817\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 2.0377e-10, 1.1686e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    22,   162] loss: 0.825\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.3060e-14, 1.3326e-16]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[12,    23,   166] loss: 0.831\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 3.2399e-11, 9.6973e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,     1,   180] loss: 0.912\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.3131e-05, 9.9997e-01, 8.5428e-12]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,     2,   162] loss: 0.846\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.6597e-03, 9.9833e-01, 1.3519e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,     3,   224] loss: 0.835\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.2449e-09, 5.0574e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,     4,   190] loss: 0.842\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.1150, 0.2633, 0.6216]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,     5,   253] loss: 0.855\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0829, 0.2062, 0.7109]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,     6,   229] loss: 0.841\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[8.6342e-05, 2.0720e-03, 9.9784e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,     7,   250] loss: 0.889\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3021, 0.3713, 0.3267]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,     8,   300] loss: 0.885\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.4717e-11, 1.0000e+00, 1.0815e-15]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,     9,   216] loss: 0.783\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[3.3491e-07, 1.3539e-03, 9.9865e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    10,   208] loss: 0.829\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[4.8913e-05, 1.5678e-08, 9.9995e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    11,   224] loss: 0.879\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.6180e-06, 1.0000e+00, 2.3873e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    12,   173] loss: 0.906\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 7.1017e-10, 1.3627e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    13,   218] loss: 0.825\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.4491e-06, 9.9998e-01, 1.9824e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    14,   218] loss: 0.858\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0041, 0.0291, 0.9668]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,    15,   210] loss: 0.842\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9996e-01, 3.5759e-05, 3.0236e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    16,   175] loss: 0.879\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0310, 0.6239, 0.3451]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,    17,   235] loss: 0.779\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.1245, 0.6819, 0.1936]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,    18,   181] loss: 0.932\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9993e-01, 8.7578e-10, 7.4973e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    19,   226] loss: 0.848\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9924e-01, 3.4779e-04, 4.1531e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    20,   178] loss: 0.847\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4694, 0.3120, 0.2186]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[13,    21,   205] loss: 0.781\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.4288e-10, 1.2274e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    22,   162] loss: 0.827\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.6059e-12, 4.8390e-17]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[13,    23,   166] loss: 0.838\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.2777e-12, 6.8214e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,     1,   180] loss: 0.905\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.7010e-08, 1.0000e+00, 1.1423e-15]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,     2,   162] loss: 0.832\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.0488e-03, 9.9895e-01, 4.5084e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,     3,   224] loss: 0.809\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 9.4360e-09, 8.0405e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,     4,   190] loss: 0.863\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0051, 0.1266, 0.8683]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,     5,   253] loss: 0.884\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0869, 0.1418, 0.7714]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,     6,   229] loss: 0.846\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.1292, 0.0439, 0.8269]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,     7,   250] loss: 0.869\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.4488, 0.2559, 0.2954]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,     8,   300] loss: 0.890\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.0774e-10, 1.0000e+00, 1.6247e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,     9,   216] loss: 0.820\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[8.8080e-08, 4.6950e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    10,   208] loss: 0.829\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.0204e-11, 4.6728e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    11,   224] loss: 0.876\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.0548e-07, 1.0000e+00, 4.3756e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    12,   173] loss: 0.909\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9980e-01, 1.7942e-09, 2.0013e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    13,   218] loss: 0.828\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.6522e-06, 9.9999e-01, 1.2235e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    14,   218] loss: 0.844\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0070, 0.2014, 0.7915]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,    15,   210] loss: 0.850\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9998e-01, 2.1989e-05, 1.3723e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    16,   175] loss: 0.866\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.1371, 0.2269, 0.6360]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,    17,   235] loss: 0.771\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0235, 0.9034, 0.0731]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,    18,   181] loss: 0.915\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9997e-01, 1.4302e-09, 2.9948e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    19,   226] loss: 0.808\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9735e-01, 8.8296e-04, 1.7677e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    20,   178] loss: 0.871\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4846, 0.2438, 0.2716]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[14,    21,   205] loss: 0.801\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.8696e-12, 5.3407e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    22,   162] loss: 0.824\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.3994e-11, 1.2643e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[14,    23,   166] loss: 0.807\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.9892e-11, 6.5126e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,     1,   180] loss: 0.865\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.1439e-05, 9.9995e-01, 4.7990e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,     2,   162] loss: 0.824\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.5365e-03, 9.9523e-01, 2.3605e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,     3,   224] loss: 0.812\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 3.9333e-08, 4.9212e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,     4,   190] loss: 0.852\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0952, 0.5266, 0.3782]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,     5,   253] loss: 0.859\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1771, 0.6085, 0.2144]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,     6,   229] loss: 0.841\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.8986e-04, 2.6654e-01, 7.3317e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,     7,   250] loss: 0.909\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3081, 0.3569, 0.3351]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,     8,   300] loss: 0.878\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.0621e-06, 1.0000e+00, 8.1688e-13]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,     9,   216] loss: 0.835\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[5.7514e-05, 2.2915e-03, 9.9765e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    10,   208] loss: 0.813\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.8095e-03, 5.5951e-05, 9.9813e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    11,   224] loss: 0.844\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.1394e-04, 9.9938e-01, 9.3361e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    12,   173] loss: 0.890\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 9.2051e-10, 8.5549e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    13,   218] loss: 0.833\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.9140e-06, 9.9995e-01, 4.9871e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    14,   218] loss: 0.849\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0054, 0.0422, 0.9524]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,    15,   210] loss: 0.858\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9990e-01, 8.9524e-05, 7.6029e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    16,   175] loss: 0.894\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0882, 0.3720, 0.5398]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,    17,   235] loss: 0.776\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.3008, 0.5204, 0.1788]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,    18,   181] loss: 0.943\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9935e-01, 8.8510e-05, 5.6522e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    19,   226] loss: 0.821\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 3.2834e-08, 1.9291e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    20,   178] loss: 0.857\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.6708, 0.1575, 0.1717]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[15,    21,   205] loss: 0.806\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.9029e-12, 4.6458e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    22,   162] loss: 0.829\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.3344e-11, 9.0680e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[15,    23,   166] loss: 0.795\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.3293e-13, 9.0249e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,     1,   180] loss: 0.886\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.3933e-06, 9.9999e-01, 2.2682e-15]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,     2,   162] loss: 0.811\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[3.1979e-06, 1.0000e+00, 1.5451e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,     3,   224] loss: 0.809\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 8.0910e-12, 5.0509e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,     4,   190] loss: 0.865\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0524, 0.3436, 0.6040]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,     5,   253] loss: 0.851\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2011, 0.4802, 0.3187]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,     6,   229] loss: 0.831\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[7.1612e-04, 8.0015e-01, 1.9913e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,     7,   250] loss: 0.878\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3823, 0.2997, 0.3180]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,     8,   300] loss: 0.886\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.0230e-12, 1.0000e+00, 2.1332e-22]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,     9,   216] loss: 0.813\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.0515e-09, 4.0531e-05, 9.9996e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    10,   208] loss: 0.836\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.8039e-09, 2.6187e-08, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    11,   224] loss: 0.872\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[7.7237e-07, 1.0000e+00, 5.8792e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    12,   173] loss: 0.885\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 8.7497e-08, 5.3515e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    13,   218] loss: 0.832\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.5242e-05, 9.9998e-01, 4.6543e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    14,   218] loss: 0.837\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.1375, 0.4268, 0.4357]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,    15,   210] loss: 0.829\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9859e-01, 1.3382e-03, 7.3207e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    16,   175] loss: 0.866\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0114, 0.8963, 0.0922]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,    17,   235] loss: 0.761\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.4103, 0.4186, 0.1711]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,    18,   181] loss: 0.904\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9992e-01, 7.9742e-07, 7.6124e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    19,   226] loss: 0.809\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 1.8687e-06, 8.1079e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    20,   178] loss: 0.864\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4870, 0.2338, 0.2791]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[16,    21,   205] loss: 0.783\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.4356e-12, 1.1381e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    22,   162] loss: 0.846\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 6.1871e-10, 1.6643e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[16,    23,   166] loss: 0.822\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.4603e-14, 1.8532e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,     1,   180] loss: 0.905\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[6.5847e-09, 1.0000e+00, 6.1872e-15]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,     2,   162] loss: 0.846\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.0867e-05, 9.9998e-01, 5.0251e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,     3,   224] loss: 0.808\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 7.0518e-08, 8.2024e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,     4,   190] loss: 0.857\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.2281, 0.0221, 0.7498]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,     5,   253] loss: 0.857\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1504, 0.5037, 0.3460]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,     6,   229] loss: 0.818\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.8096e-05, 1.2861e-01, 8.7137e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,     7,   250] loss: 0.859\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3336, 0.3738, 0.2926]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,     8,   300] loss: 0.870\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.2930e-06, 9.9999e-01, 4.4683e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,     9,   216] loss: 0.828\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[7.8337e-09, 1.0024e-04, 9.9990e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    10,   208] loss: 0.813\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[3.2295e-05, 1.7035e-04, 9.9980e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    11,   224] loss: 0.820\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.4470e-09, 1.0000e+00, 3.3648e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    12,   173] loss: 0.864\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.6071e-11, 2.6588e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    13,   218] loss: 0.837\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[9.7076e-06, 9.9999e-01, 1.3570e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    14,   218] loss: 0.807\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0020, 0.0090, 0.9891]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,    15,   210] loss: 0.825\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9998e-01, 9.4846e-06, 1.0876e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    16,   175] loss: 0.889\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0413, 0.8717, 0.0870]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,    17,   235] loss: 0.760\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.2994, 0.5728, 0.1278]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,    18,   181] loss: 0.891\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.5047e-01, 1.0469e-04, 4.9425e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    19,   226] loss: 0.805\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 2.4906e-06, 1.0544e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    20,   178] loss: 0.832\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.2981, 0.3747, 0.3272]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[17,    21,   205] loss: 0.792\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.0343e-13, 7.7257e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    22,   162] loss: 0.795\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 4.0830e-09, 1.5585e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[17,    23,   166] loss: 0.795\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.0146e-10, 8.2003e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,     1,   180] loss: 0.893\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.6810e-07, 1.0000e+00, 3.4032e-17]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,     2,   162] loss: 0.842\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.5074e-04, 9.9985e-01, 2.0919e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,     3,   224] loss: 0.806\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.2580e-06, 7.5854e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,     4,   190] loss: 0.829\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.2993, 0.1833, 0.5174]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[18,     5,   253] loss: 0.835\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3573, 0.2196, 0.4232]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[18,     6,   229] loss: 0.808\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.2171e-04, 1.4403e-02, 9.8548e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,     7,   250] loss: 0.896\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.5214, 0.1796, 0.2990]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[18,     8,   300] loss: 0.857\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.7769e-09, 1.0000e+00, 9.4619e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,     9,   216] loss: 0.781\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.3709e-05, 7.8717e-04, 9.9920e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    10,   208] loss: 0.810\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[8.2366e-07, 1.2756e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    11,   224] loss: 0.843\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.5282e-07, 1.0000e+00, 2.1959e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    12,   173] loss: 0.871\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9966e-01, 3.6952e-08, 3.3888e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    13,   218] loss: 0.800\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.2440e-08, 1.0000e+00, 2.9948e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    14,   218] loss: 0.819\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[9.6601e-05, 2.3705e-01, 7.6285e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    15,   210] loss: 0.794\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.8431e-01, 1.5601e-02, 9.0613e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    16,   175] loss: 0.848\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0604, 0.9317, 0.0078]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[18,    17,   235] loss: 0.773\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.5097, 0.2449, 0.2454]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[18,    18,   181] loss: 0.893\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9969e-01, 2.6314e-08, 3.0782e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    19,   226] loss: 0.808\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9998e-01, 9.5160e-06, 1.5312e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    20,   178] loss: 0.812\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.8836, 0.0463, 0.0701]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[18,    21,   205] loss: 0.795\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 3.6996e-11, 4.1849e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    22,   162] loss: 0.796\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.4188e-14, 1.2138e-19]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[18,    23,   166] loss: 0.798\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.7786e-07, 4.2192e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,     1,   180] loss: 0.853\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.4306e-06, 1.0000e+00, 5.9867e-13]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,     2,   162] loss: 0.844\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.5958e-03, 9.9840e-01, 2.7408e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,     3,   224] loss: 0.816\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 7.3739e-12, 9.9900e-11]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,     4,   190] loss: 0.819\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0442, 0.3680, 0.5877]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[19,     5,   253] loss: 0.843\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.1299, 0.2284, 0.6416]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[19,     6,   229] loss: 0.816\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[2.9743e-06, 2.5245e-02, 9.7475e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,     7,   250] loss: 0.860\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.3917, 0.2946, 0.3138]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[19,     8,   300] loss: 0.857\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.1352e-10, 1.0000e+00, 6.4422e-22]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,     9,   216] loss: 0.799\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[6.1908e-10, 8.7690e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    10,   208] loss: 0.821\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[8.1551e-10, 3.0277e-11, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    11,   224] loss: 0.818\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.9161e-08, 1.0000e+00, 4.4806e-10]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    12,   173] loss: 0.851\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.8480e-08, 1.3582e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    13,   218] loss: 0.811\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[5.2665e-07, 9.9999e-01, 9.9311e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    14,   218] loss: 0.801\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.6827e-04, 4.4932e-03, 9.9534e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    15,   210] loss: 0.797\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 1.0439e-06, 3.2142e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    16,   175] loss: 0.854\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.0020, 0.1404, 0.8576]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[19,    17,   235] loss: 0.731\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.5887, 0.2138, 0.1975]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[19,    18,   181] loss: 0.897\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9956e-01, 3.0921e-09, 4.4402e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    19,   226] loss: 0.785\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9736e-01, 5.3225e-04, 2.1083e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    20,   178] loss: 0.832\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.3495, 0.3413, 0.3092]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[19,    21,   205] loss: 0.774\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 7.9763e-14, 1.5727e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    22,   162] loss: 0.776\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 4.2790e-08, 1.2669e-15]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[19,    23,   166] loss: 0.774\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.3127e-12, 2.8801e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,     1,   180] loss: 0.854\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.6897e-08, 1.0000e+00, 2.2924e-13]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,     2,   162] loss: 0.841\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.2311e-03, 9.9763e-01, 1.3459e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,     3,   224] loss: 0.776\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 8.3879e-09, 3.4990e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,     4,   190] loss: 0.828\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0336, 0.1329, 0.8335]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,     5,   253] loss: 0.793\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.0544, 0.3017, 0.6439]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,     6,   229] loss: 0.821\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.0012, 0.0060, 0.9929]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,     7,   250] loss: 0.876\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.2983, 0.3774, 0.3243]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,     8,   300] loss: 0.856\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.2730e-11, 1.0000e+00, 8.2404e-19]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,     9,   216] loss: 0.797\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[3.7078e-11, 1.0411e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    10,   208] loss: 0.821\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[1.3657e-07, 1.2034e-08, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    11,   224] loss: 0.832\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[1.7931e-04, 9.9982e-01, 5.0838e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    12,   173] loss: 0.870\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 2.6795e-08, 1.9995e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    13,   218] loss: 0.781\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[2.4072e-06, 1.0000e+00, 5.6814e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    14,   218] loss: 0.807\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[4.2958e-06, 9.8597e-01, 1.4025e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    15,   210] loss: 0.780\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9991e-01, 8.8726e-05, 4.4527e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    16,   175] loss: 0.824\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[4.9944e-04, 7.3115e-01, 2.6836e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    17,   235] loss: 0.730\n",
      "Actual:  tensor([1], device='cuda:0')\n",
      "predicted:  tensor([[0.2291, 0.4464, 0.3245]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,    18,   181] loss: 0.899\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9975e-01, 3.9793e-11, 2.4957e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    19,   226] loss: 0.796\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[0.9955, 0.0021, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,    20,   178] loss: 0.814\n",
      "Actual:  tensor([2], device='cuda:0')\n",
      "predicted:  tensor([[0.4981, 0.2395, 0.2624]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "[20,    21,   205] loss: 0.774\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[9.9999e-01, 9.8501e-09, 8.1559e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    22,   162] loss: 0.818\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 3.4082e-08, 2.7504e-14]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "[20,    23,   166] loss: 0.802\n",
      "Actual:  tensor([0], device='cuda:0')\n",
      "predicted:  tensor([[1.0000e+00, 5.6448e-09, 2.2680e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Init Agent\n",
    "#train_agent = NeurosmashAgent()   \n",
    "print(train_agent)\n",
    "train_agent.training = True\n",
    "#Enable GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  train_agent.cuda()\n",
    "\n",
    "#Training CNN\n",
    "N_epochs = 20\n",
    "\n",
    "#Fitting CNN model:\n",
    "#Loss Function\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "#Optimizer\n",
    "optimizer = torch.optim.Adam(train_agent.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    for i,game in enumerate(experience_replay):\n",
    "        #Reset loss counter\n",
    "        running_loss = 0.0\n",
    "        for j,steps in enumerate(game):\n",
    "            state, action = steps[0], steps[1]\n",
    "\n",
    "            state_norm = [s / 255 for s in state]            \n",
    "            state_tensor = torch.tensor(state_norm, dtype=torch.float).view(3, 256, 256).view(1, 3, 256, 256).cuda()\n",
    "\n",
    "            action_tensor = torch.tensor(action, dtype=torch.long).view(1).cuda()\n",
    "            #print(\"Actual: \", action_tensor)\n",
    "                    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = train_agent(state_tensor)\n",
    "            #print(\"Predicted: \", outputs)\n",
    "\n",
    "            loss = loss_func(outputs, action_tensor)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            #if (i+1) % 10 == 0:    # print every 10 steps\n",
    "        print('[%d, %5d, %5d] loss: %.3f' %\n",
    "        (epoch + 1,  i + 1,j+1,  running_loss / j ))\n",
    "        running_loss = 0.0\n",
    "        print(\"Actual: \", action_tensor)\n",
    "        print(\"predicted: \", outputs)\n",
    "# #Save trained agent's brain\n",
    "torch.save(train_agent.state_dict(), \"/content/drive/My Drive/NIPS/model_3.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHBAY-wjdWDs"
   },
   "source": [
    "#Check some predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhbtYOr3LSdi"
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save(train_agent.state_dict(), \"/content/drive/My Drive/NIPS/model_2.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neurosmash_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
